{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code used to train a cGAN to generate DEMs conditioned to rgb satellite images in google Colab (GPU accelerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10216,
     "status": "ok",
     "timestamp": 1582571308114,
     "user": {
      "displayName": "manolis panagiotou",
      "photoUrl": "",
      "userId": "09197886876966874303"
     },
     "user_tz": -120
    },
    "id": "xDCbkhJMFgAQ",
    "outputId": "b11de395-95bc-4c4e-bf01-e2c9ac7d0a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import sys\n",
    "import imageio\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BoMKTptRFvW4"
   },
   "outputs": [],
   "source": [
    "#Input image = satellite, Real Image = DEM\n",
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "INPUT_CHANNELS = 3\n",
    "OUTPUT_CHANNELS = 1\n",
    "LAMBDA = 100\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnPYB7qNFzkT"
   },
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def random_crop(input_image, real_image):\n",
    "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]\n",
    "\n",
    "\n",
    "# normalizing the images to [-1, 1]\n",
    "\n",
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "@tf.function()\n",
    "def random_jitter(input_image, real_image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # random mirroring\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def load_image_train(input_image, real_image):\n",
    "    # real_image = tf.image.grayscale_to_rgb(real_image)\n",
    "    # input_image, real_image = random_jitter(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "    # real_image = tf.image.rgb_to_grayscale(real_image)\n",
    "    return input_image, real_image\n",
    "\n",
    "def load_image_test(input_image, real_image):\n",
    "    # real_image = tf.image.grayscale_to_rgb(real_image)\n",
    "    # input_image, real_image = random_jitter(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "    # real_image = tf.image.rgb_to_grayscale(real_image)\n",
    "    return input_image, real_image\n",
    "\n",
    "    return input_image, real_image\n",
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "\t# load compressed arrays\n",
    "\tdata = np.load(filename)\n",
    "\t# unpack arrays\n",
    "\tX1, X2 = data['arr_0'], data['arr_1']\n",
    "\treturn [X1, X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45414,
     "status": "ok",
     "timestamp": 1582571343338,
     "user": {
      "displayName": "manolis panagiotou",
      "photoUrl": "",
      "userId": "09197886876966874303"
     },
     "user_tz": -120
    },
    "id": "gJRssTdQF1NW",
    "outputId": "59b62359-5c20-47fe-bf56-19f1c24b599e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "Loaded (196, 256, 256, 3) (196, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "path = '/content/drive/My Drive/ImageToDEM/'\n",
    "sys.path.append(path)\n",
    "# load image data\n",
    "dataset = load_real_samples(path + 'Data/Atacama.npz')\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "dataset[0] = tf.cast(dataset[0],tf.float32)\n",
    "dataset[1] = tf.cast(dataset[1],tf.float32)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dataset[0], dataset[1]))\n",
    "train_dataset = train_dataset.map(load_image_train)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5c1qqm1D8vO"
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result\n",
    "\n",
    "down_model = downsample(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHMhXC6uEWQq"
   },
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result\n",
    "\n",
    "up_model = upsample(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdSv5Rm0EbR-"
   },
   "outputs": [],
   "source": [
    "def Generator(input_channels=INPUT_CHANNELS, output_channels=OUTPUT_CHANNELS):\n",
    "  down_stack = [\n",
    "    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "    downsample(128, 4), # (bs, 64, 64, 128)\n",
    "    downsample(256, 4), # (bs, 32, 32, 256)\n",
    "    downsample(512, 4), # (bs, 16, 16, 512)\n",
    "    downsample(512, 4), # (bs, 8, 8, 512)\n",
    "    downsample(512, 4), # (bs, 4, 4, 512)\n",
    "    downsample(512, 4), # (bs, 2, 2, 512)\n",
    "    downsample(512, 4), # (bs, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "    upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "    upsample(256, 4), # (bs, 32, 32, 512)\n",
    "    upsample(128, 4), # (bs, 64, 64, 256)\n",
    "    upsample(64, 4), # (bs, 128, 128, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(output_channels, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "  concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "  inputs = tf.keras.layers.Input(shape=[None,None,input_channels])\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = concat([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5A5tvxaTEpq0"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOeP-4LaFFl8"
   },
   "outputs": [],
   "source": [
    "def Discriminator(input_channels=INPUT_CHANNELS, output_channels=OUTPUT_CHANNELS):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  inp = tf.keras.layers.Input(shape=[None, None, input_channels], name='input_image')\n",
    "  tar = tf.keras.layers.Input(shape=[None, None, output_channels], name='target_image')\n",
    "\n",
    "  x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "  down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "  down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "  down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvE7wVUEFcbG"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  # mean absolute error\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhlw_-V_OQ6Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_images(model, test_input, tar):\n",
    "  prediction = model(test_input, training=True)\n",
    "  plt.figure(figsize=(15,15))\n",
    "\n",
    "  display_list = [test_input[0], tar[0], prediction[0]]\n",
    "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    if(display_list[i].shape[2] == 1):\n",
    "      display_list[i] = tf.image.grayscale_to_rgb(display_list[i])\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "def save_images(model, test_input, tar, e, path):\n",
    "  prediction = model(test_input, training=True)\n",
    "  plt.figure(figsize=(15,15))\n",
    "\n",
    "  display_list = [test_input[0], tar[0], prediction[0]]\n",
    "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    if(display_list[i].shape[2] == 1):\n",
    "      display_list[i] = tf.image.grayscale_to_rgb(display_list[i])\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.savefig(path + \"/epoch_\"+ str(e) + '.png')\n",
    "  print(path + \"/epoch_\"+ str(e) + '.png')\n",
    "  \n",
    "def save_pretty(model, pretty, e, path):\n",
    "  k = 0\n",
    "  for l in range(len(pretty[0])):\n",
    "    if not os.path.isdir(path + \"/epoch\" + str(e)):\n",
    "      os.mkdir(path + \"/epoch\" + str(e))\n",
    "\n",
    "    pretty_input = (pretty[0][l]/127.5)-1\n",
    "    pretty_input =  tf.cast(pretty_input,tf.float32)\n",
    "    pretty_input = tf.expand_dims(pretty_input, 0)\n",
    "    pretty_target = (pretty[1][l]/127.5) -1\n",
    "    prediction = model(pretty_input, training=True)\n",
    "    imageio.imwrite(path + \"/epoch\" + str(e) + \"/pretty_\"+ str(k) + 'pred.png', np.uint8( 255 * np.array(prediction[0] * 0.5 + 0.5)))\n",
    "    imageio.imwrite(path + \"/epoch\" + str(e) + \"/pretty_\"+ str(k) + 'in.png', np.uint8( 255 * np.array(pretty_input[0] * 0.5 + 0.5)))\n",
    "    imageio.imwrite(path + \"/epoch\" + str(e) + \"/pretty_\"+ str(k) + 'tar.png', np.uint8( 255 * np.array(pretty_target * 0.5 + 0.5)))\n",
    "    k += 1\n",
    "\n",
    "def savedata(dataname, *data):\n",
    "  with open(dataname, 'a') as fd:\n",
    "    writer = csv.writer(fd)\n",
    "    writer.writerow(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PrE-Jm3OTo2"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target):\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gen_output = generator(input_image, training=True)\n",
    "\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "    gen_loss, gan_loss, l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "  generator_gradients = gen_tape.gradient(gen_loss,\n",
    "                                          generator.trainable_variables)\n",
    "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "  return gen_loss, gan_loss, l1_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0j6KrshDOWqs"
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds, pretty=[], validation = []):\n",
    "  dataname = \"/content/drive/My Drive/ImageToDEM/ncGAN/models/results/ncGANData.csv\"\n",
    "  if(pretty):\n",
    "    print(\"Pretty Images chosen\")\n",
    "    for k in range(len(pretty[0])):\n",
    "\n",
    "      pretty_input = (pretty[0][k]/127.5)-1\n",
    "      pretty_target = (pretty[1][k]/127.5) -1\n",
    "      display_list = [pretty_input, pretty_target]\n",
    "      title = ['Pretty Image', 'Ground Truth']\n",
    "      for i in range(2):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        if(display_list[i].shape[2] == 1):\n",
    "          plt.imshow(display_list[i][:, :, 0]*0.5 + 0.5, cmap='gray')\n",
    "        else:\n",
    "          plt.imshow(display_list[i]*0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "      plt.show()\n",
    "  epoch_times = []\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    # Train\n",
    "    l1Avg = []\n",
    "    genAvg = []\n",
    "    ganAvg = []\n",
    "    discAvg = []\n",
    "    for input_image, target in train_ds:\n",
    "      gen_loss, gan_loss, l1_loss, disc_loss = train_step(input_image, target)\n",
    "      l1Avg.append(l1_loss)\n",
    "      genAvg.append(gen_loss)\n",
    "      ganAvg.append(gan_loss)\n",
    "      discAvg.append(disc_loss)\n",
    "\n",
    "\n",
    "\n",
    "    # for val\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    l1AvgVal = []\n",
    "    genAvgVal = []\n",
    "    ganAvgVal = []\n",
    "    discAvgVal = []\n",
    "    for input_imageval, targetval in validation:\n",
    "      gen_output = generator(input_imageval, training=False)\n",
    "      disc_real_output = discriminator([input_imageval, targetval], training=False)\n",
    "      disc_generated_output = discriminator([input_imageval, gen_output], training=False)\n",
    "\n",
    "      gen_loss, gan_loss, l1_loss = generator_loss(disc_generated_output, gen_output, targetval)\n",
    "      disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "      l1AvgVal.append(l1_loss)\n",
    "      genAvgVal.append(gen_loss)\n",
    "      ganAvgVal.append(gan_loss)\n",
    "      discAvgVal.append(disc_loss)\n",
    "\n",
    "    L1Loss = np.mean(l1Avg)\n",
    "    genLoss = np.mean(genAvg)\n",
    "    ganLoss = np.mean(ganAvg)\n",
    "    discLoss = np.mean(discAvg)\n",
    "\n",
    "    ValL1Loss = np.mean(l1AvgVal)\n",
    "    ValgenLoss = np.mean(genAvgVal)\n",
    "    ValganLoss = np.mean(ganAvgVal)\n",
    "    ValdiscLoss = np.mean(discAvgVal)\n",
    "\n",
    "    \n",
    "    savedata(dataname, epoch, L1Loss, genLoss, ganLoss, discLoss, ValL1Loss, ValgenLoss, ValganLoss, ValdiscLoss)\n",
    "    epoch_times.append(time.time()-start)\n",
    "    # Test on the same image so that the progress of the model can be \n",
    "    # easily seen.\n",
    "    # for example_input, example_target in test_ds.take(1):\n",
    "    #   generate_images(generator, example_input, example_target)\n",
    "    #   save_images(generator, example_input, example_target, epoch, '/content/drive/My Drive/ImageToDEM/ncGAN/models/results')\n",
    "    if(pretty):\n",
    "      save_pretty(generator, pretty, epoch, '/content/drive/My Drive/ImageToDEM/ncGAN/models/pretty')\n",
    "    # saving (checkpoint) the model every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0 or epoch==0:\n",
    "      tf.saved_model.save(generator, '/content/drive/My Drive/ImageToDEM/ncGAN/models')\n",
    "      print('Model saved')\n",
    "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                        time.time()-start))\n",
    "    print ('Estimated Time left for remaining {} epochs is {} sec = {} hours\\n'.format(epochs - epoch - 1, (epochs - epoch - 1) * sum(epoch_times) / len(epoch_times), (epochs - epoch - 1) * sum(epoch_times) / len(epoch_times)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47218,
     "status": "ok",
     "timestamp": 1582571345201,
     "user": {
      "displayName": "manolis panagiotou",
      "photoUrl": "",
      "userId": "09197886876966874303"
     },
     "user_tz": -120
    },
    "id": "V4U2nqId0xCs",
    "outputId": "19d5c90f-c402-4ebf-8c73-c9874f3bd07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (16, 256, 256, 3) (16, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# load image data\n",
    "datasetT = load_real_samples(path + 'DataAll/TestPrettyRGB.npz')\n",
    "\n",
    "pretty = [5, 6, 11, 13]\n",
    "pretty_dataset = ([datasetT[0][x] for x in pretty], [datasetT[1][x] for x in pretty])\n",
    "\n",
    "print('Loaded', datasetT[0].shape, datasetT[1].shape)\n",
    "datasetT[0] = tf.cast(datasetT[0],tf.float32)\n",
    "datasetT[1] = tf.cast(datasetT[1],tf.float32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((datasetT[0], datasetT[1]))\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.shuffle(BUFFER_SIZE)\n",
    "test_dataset = test_dataset.batch(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49134,
     "status": "ok",
     "timestamp": 1582571347129,
     "user": {
      "displayName": "manolis panagiotou",
      "photoUrl": "",
      "userId": "09197886876966874303"
     },
     "user_tz": -120
    },
    "id": "LEnaz_JtFsAP",
    "outputId": "7e0e13da-53d4-4f81-d2eb-fd7f4e340b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (241, 256, 256, 3) (241, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# load image data\n",
    "datasetVal = load_real_samples(path + 'DataAll/ValidateAllRGB.npz')\n",
    "\n",
    "print('Loaded', datasetVal[0].shape, datasetVal[1].shape)\n",
    "datasetVal[0] = tf.cast(datasetVal[0],tf.float32)\n",
    "datasetVal[1] = tf.cast(datasetVal[1],tf.float32)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((datasetVal[0], datasetVal[1]))\n",
    "validation_dataset = validation_dataset.map(load_image_test)\n",
    "validation_dataset = validation_dataset.shuffle(BUFFER_SIZE)\n",
    "validation_dataset = validation_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onNIf43UGoy-"
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('/content/drive/My Drive/ImageToDEM/ncGAN/models'):\n",
    "  os.mkdir('/content/drive/My Drive/ImageToDEM/ncGAN/models')\n",
    "if not os.path.isdir('/content/drive/My Drive/ImageToDEM/ncGAN/models/pretty'):\n",
    "  os.mkdir('/content/drive/My Drive/ImageToDEM/ncGAN/models/pretty')\n",
    "if not os.path.isdir('/content/drive/My Drive/ImageToDEM/ncGAN/models/results'):\n",
    "  os.mkdir('/content/drive/My Drive/ImageToDEM/ncGAN/models/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 837,
     "status": "ok",
     "timestamp": 1582576682032,
     "user": {
      "displayName": "manolis panagiotou",
      "photoUrl": "",
      "userId": "09197886876966874303"
     },
     "user_tz": -120
    },
    "id": "3XSJGFHLOhuC",
    "outputId": "dbf61d76-cdf9-4209-ebfa-24eb85444c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/ImageToDEM/ncGAN/models/assets\n",
      "Model saved\n",
      "Time taken for epoch 300 is 25.077869653701782 sec\n",
      "\n",
      "Estimated Time left for remaining 0 epochs is 0.0 sec = 0.0 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(train_dataset, EPOCHS, pretty_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1ikVirBtBsyuPxV5OC1eBPTzP4iabVM8-"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8844,
     "status": "ok",
     "timestamp": 1582576690869,
     "user": {
      "displayName": "manolis panagiotou",
      "photoUrl": "",
      "userId": "09197886876966874303"
     },
     "user_tz": -120
    },
    "id": "XNjVmeow01P1",
    "outputId": "b74e24a6-82d2-4f57-cf28-d387d2b70fb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the trained model on the entire test dataset\n",
    "for inp, tar in test_dataset:\n",
    "  generate_images(generator, inp, tar)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train.ipynb",
   "provenance": [
    {
     "file_id": "1EZG17DsPY8FqeZ_IRGBUgVEy_0zJp9ts",
     "timestamp": 1574703069216
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
